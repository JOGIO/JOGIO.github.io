<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ubuntu 16.04下搭建hadoop-3.0.3]]></title>
    <url>%2F2019%2F01%2F26%2Fubuntu-16-04%E4%B8%8B%E6%90%AD%E5%BB%BAhadoop-3-0-3%2F</url>
    <content type="text"><![CDATA[大数据平台搭建踩坑第二弹，Hadoop平台搭建，2.x版本已经有很多教程了，3.0以上版本加入了新特性猛得一匹，所以就来踩踩坑吧——Hadoop3.0.3搭建 安装环境UBUNTU 16.04 虚拟机4台，一台master，三台segment，以下都是在greenplum搭建的第二步集群配置的基础上进行的 JDK安装这一步在所有虚拟机上操作都是一样的 -下载安装添加ppa并安装java1.8 sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer 完成后java -version查看是否成功 -环境配置使用apt-get下载得扎瓦需要自己去找一下他的位置，一般在/usr/lib/jvm文件夹下，java的文件夹名看自己的，我的是java-8-oracle 打开终端 sudo gedit /etc/profile 加上下面几句话 export JAVA_HOME=/usr/lib/jvm/java-8-oralce export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 保存退出 source /etc/profile就ok了 Hadoop3.0.3以下步骤先在master上进行，完成后将文件夹拷贝到其他机器即可 -下载我的用户名为gpadmin，在/home/gpadmin/文件夹下新建文件夹local cd /home/gpadmin mkdir local 下载镜像 wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.0.3/hadoop-3.0.3.tar.gz 原地解压 tar zxvf hadoop-3.0.3.tar.gz 或者双击打开拖出来 -文件配置进入/home/gpadmin/hadoop-3.0.3/etc文件夹下，配置文件全在这里 —core-site.xml用sudo gedit core-site.xml或者双击打开配置如下 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop3/tmp&lt;/value&gt; &lt;/configuration&gt; 其中master为hostname —hdfs-site.xml配置如下 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;4&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop3/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop3/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; —mapred-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt; /usr/local/hadoop3/etc/hadoop, /usr/local/hadoop3/share/hadoop/common/*, /usr/local/hadoop3/share/hadoop/common/lib/*, /usr/local/hadoop3/share/hadoop/hdfs/*, /usr/local/hadoop3/share/hadoop/hdfs/lib/*, /usr/local/hadoop3/share/hadoop/mapreduce/*, /usr/local/hadoop3/share/hadoop/mapreduce/lib/*, /usr/local/hadoop3/share/hadoop/yarn/*, /usr/local/hadoop3/share/hadoop/yarn/lib/* &lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; —yarn-site.xml&lt;configuration&gt; &lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;ha01&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; —workers添加从机得hostname,稍后会配置 segment1 segment2 segment3 —hadoop-env.shJAVA_HOME=/usr/lib/jvm/java-8-oracle —环境变量sudo gedit /etc/profile编辑环境变量export HADOOP_HOME=/home/hadoop/hadoop3.03export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH source /etc/profile生效 -拷贝分发使用scp命令scp -r 源地址 目的地址在master机器的/home/gpadmin/local文件夹下打开终端 scp -r hadoop-3.0.3 gpadmin@segment1:/home/gpadmin/local scp -r hadoop-3.0.3 gpadmin@segment2:/home/gpadmin/local scp -r hadoop-3.0.3 gpadmin@segment3:/home/gpadmin/local 免密ssh登陆配置这里有一个带坑 hadoop3.0以上的版本需要在root权限下进行运行，否则会出现 namenode can only be executred by root 。ssh和普通用户的ssh是分开的，普通用户就在/home/用户名/.ssh下，root用户在/root/.ssh下。 -生成密钥在master打开终端su进root apt-get install ssh cd /root/.ssh ssh-keygen -t rsa -P &apos;&apos; 如果没有authorized_keys文件就touch authorized_keys新建一个之后继续把公钥加入authorized——keys cat id_rsa.pub &gt;&gt; authorized_keys 验证是否成功 ssh localhost 在每台机器上重复以上步骤 这里又有一个带坑，如果root的ssh登陆显示permission denied, please try again则需要sudo gedit /etc/ssh/sshd_config,把PermitRootLogin without-password 改为PermitRootLogin yes -交换密钥在master打开终端su进root，用以下语句把master的公钥发送到segment下，并重命名为master.pub scp /root/.ssh/ida_rsa.pub root@segment1:/root/.ssh/master.pub scp /root/.ssh/ida_rsa.pub root@segment2:/root/.ssh/master.pub scp /root/.ssh/ida_rsa.pub root@segment3:/root/.ssh/master.pub 分别在每台segment机上打开终端，可以直接打开虚拟机，也可以在master机上 ssh segment1登陆上去进行操作 su cd /root/.ssh cat master.pub &gt;&gt; authorized_keys 这样就把master的公钥加入到segment的授权名单里了，理论上master就可以免密登陆segment了。 启动在hadoop-3.0.3文件夹下打开终端su成root ./bin/hdfs namenode -format ./sbin/start-dfs.sh 之后就能登陆localhost:8088和9870查看了]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何搭建JO厨的奇妙博客]]></title>
    <url>%2F2019%2F01%2F19%2F%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BAJO%E5%8E%A8%E7%9A%84%E5%A5%87%E5%A6%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[前言在一次突发奇想觉得该记录一下我做的各种事情后，便开始有了搭建一个博客的想法。 但是普通的主题或者其他的吧，就感觉挺没有逼格的，刚好记得有人说过可以用JOJO主题做博客，便疯狂百度如何用自定义自己的博客，历经各种意外事件最后好歹也算搭建起来了，搭建完确认无误之后第一件事那必是记录下搭建博客的整个过程。(不过刚好赶上报告的deadline，写报告加开会拖了好久) 前言，我不建议没有替身的人搭建主题博客，虽说过程不是很复杂，但是对于没有替身的人可能看着攻略也弄不好。 先把坑留好吧，以后再慢慢填。 音乐背景字体]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>奇妙的东西</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UBUNTU16.04上的greenplum搭建]]></title>
    <url>%2F2019%2F01%2F19%2FUBUNTU16-04%E4%B8%8A%E7%9A%84greenplum%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[环境准备4台ubuntu16.04 集群配置(hostname、hosts配置) 实现hostname映射到ip地址，在后续配置文件中需要用hostname进行配置，为方便记忆，master的hostname为gp-master，segment的hostname为gp-segment1到gp-segment3 Master配置su进入root 更改主机名、配置hosts文件，通过主机名找到ip地址 echo &apos;gp-master&apos; &gt; /etc/hostname echo &apos;192.168.0.100 gp-master&apos; &gt;&gt; /etc/hosts echo &apos;192.168.0.101 gp-segment1&apos; &gt;&gt; /etc/hosts echo &apos;192.168.0.102 gp-segment2&apos; &gt;&gt; /etc/hosts echo &apos;192.168.0.103 gp-segment3&apos; &gt;&gt; /etc/hosts segement配置与master基本相同，其中 echo &apos;gp-master&apos; &gt; /etc/hostname 中的’gp-master’改为对应的segment1到3 新建用户 这一步的意义在于之后的实现中需要在每台机子的相同位置创建一个文件夹用于存储，ubuntu的home路径其实为/home/用户名/… ,如果几台机子本来的用户名不同home路径就不同，则需要在系统根目录创建，根目录有权限限制，这样还需要多一步配置文件夹权限的步骤 master、segement操作相同adduser gpadmin echo &apos;gpadmin ALL=(ALL:ALL) ALL&apos; &gt;&gt; /etc/sudoers reboot 重启后登录新建的gpadmin su gpadmin 新建文件夹mastermkdir /gpmaster master、segmentmkdir /primary 安装master、segmentcd ~ sudo apt-get install python-software-properties sudo apt-get install software-properties-common sudo add-apt-repository ppa:greenplum/db sudo apt-get update sudo apt-get install greenplum-db-oss 秘钥交换之后的操作全在master进行打开一个新的命令窗，加载greenplum专用环境变量 source /opt/gpdb/greenplum_path.sh 创建主机列表文件 touch hostlist_singlenode echo &apos;gp-master&apos; &gt;&gt; hostlist_singlenode echo &apos;gp-segment1&apos; &gt;&gt; hostlist_singlenode echo &apos;gp-segment2&apos; &gt;&gt; hostlist_singlenode echo &apos;gp-segment3&apos; &gt;&gt; hostlist_singlenode 秘钥交换 gpssh-exkeys -f hostlist_singlenode 配置文件复制配置文件到/home目录 cd ~ cp $GPHOME/docs/cli_help/gpconfigs/gpinitsystem_singlenode . 使用gedit打开复制来的gpinitsystem_singlenode进行一下配置：MACHINE_LIST_FILE=./hostlist_singlenode declare -a DATA_DIRECTORY=(/home/gpadmin/primary) MASTER_HOSTNAME=gp-master MASTER_DIRECTORY=/home/gpadmin/gpmaster 上面的DATA_DIRECTORY就是之前说的要每台机子路径相同的数据存储文件夹，这里还有个骚用法可以用空格隔开写多个文件夹进去例如（/home/gpadmin/data1 /home/gpadmin/data2），这样每台机子的文件夹会翻倍，最后系统的节点也会翻倍，一般一个cpu设置 初始化回到秘钥交换时的命令窗口，输入 /opt/gpdb/bin/gpinitsystem -c gpinitsystem_singlenode 他会问是否继续，默认是否，输入y回车继续 也许会报错说环境变量没有MASTER_DATA_DIRECTORY，输入 export MASTER_DATA_DIRECTORY=/home/gpadmin/gpmaster/gpsne-1 测试以下是官网的操作 createdb demo psql demo create table foo(id int); insert into foo values(1); select * from foo; seletc * from gp_segment_configuration 使用每次打开新的命令窗，都需要重新引入环境变量 source /opt/gpdb/greenplum_path.sh export MASTER_DATA_DIRECTORY=/home/gpadmin/gpmaster/gpsne1 启动 gpstart登录 psql停止 gpstop更多操作建议百度]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F16%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
